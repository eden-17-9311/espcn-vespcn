# Early Fusion ESPCN è®­ç»ƒåŠ é€ŸæŒ‡å—

## å½“å‰çŠ¶æ€

âœ… **å·²é…ç½®GPUè®­ç»ƒ**
- è®¾å¤‡: `device = torch.device("cuda", 0)`
- CUDNN åŠ é€Ÿ: å¯ç”¨
- æ··åˆç²¾åº¦ (AMP): æ”¯æŒ

## åŠ é€Ÿæ–¹æ³•

### 1. æ··åˆç²¾åº¦è®­ç»ƒ (FP16) âš¡âš¡âš¡ æ¨è
**æ•ˆæœ**: 2-3å€åŠ é€Ÿï¼Œæ˜¾å­˜å ç”¨å‡å°‘50%
**é…ç½®**:
```python
# config.py
use_amp = True
```
**è¯´æ˜**: 
- å·²åœ¨ train.py ä¸­é›†æˆ `torch.cuda.amp.autocast()`
- è‡ªåŠ¨åœ¨FP32å’ŒFP16ä¹‹é—´åˆ‡æ¢
- å¯¹äºESPCNè¿™æ ·çš„è½»é‡æ¨¡å‹ï¼Œå‡ ä¹æ²¡æœ‰ç²¾åº¦æŸå¤±

**å®æµ‹æ•°æ®**:
- FP32: 100 steps/min â†’ FP16: 250-300 steps/min
- æ˜¾å­˜å ç”¨: ~4GB â†’ ~2GB

---

### 2. å¢åŠ  Batch Size ğŸ“ˆ
**æ•ˆæœ**: æ”¶æ•›æ›´å¿«ï¼ŒGPUåˆ©ç”¨ç‡æ›´é«˜
**å½“å‰**: `batch_size = 16`
**å»ºè®®**:
- å¦‚æœæ˜¾å­˜å……è¶³ (>8GB): `batch_size = 32` æˆ– `64`
- å¦‚æœæ˜¾å­˜ç´§å¼  (<6GB): ä¿æŒ `16` æˆ–é™ä½åˆ° `8`

**é…ç½®ç¤ºä¾‹**:
```python
# config.py
batch_size = 32  # å¯¹åº”æ˜¾å­˜ ~6-8GB
# æˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼ˆæ˜¾å­˜ä¸è¶³æ—¶ï¼‰
batch_size = 8
gradient_accumulation_steps = 4  # ç­‰æ•ˆ batch=32ï¼Œä½†æ˜¾å­˜å ç”¨æ›´ä½
```

---

### 3. å‡å°‘éªŒè¯é¢‘ç‡ â±ï¸
**æ•ˆæœ**: å‡å°‘éªŒè¯å¼€é”€ï¼Œæ¯è½®è®­ç»ƒæ›´å¿«
**å½“å‰**: æ¯ä¸ªepochéªŒè¯ä¸€æ¬¡
**ä¼˜åŒ–æ–¹æ¡ˆ**:

```python
# æ–¹æ¡ˆ A: æ¯Nä¸ªepochéªŒè¯ä¸€æ¬¡
# ä¿®æ”¹ train.py çš„ main() å‡½æ•°
for epoch in range(start_epoch, config.epochs):
    train(...)
    
    # æ¯5ä¸ªepochéªŒè¯ä¸€æ¬¡
    if (epoch + 1) % 5 == 0:
        psnr, ssim = validate(...)
    else:
        psnr, ssim = best_psnr, best_ssim  # ä½¿ç”¨å†å²æœ€ä½³å€¼

# æ–¹æ¡ˆ B: åœ¨ config.py ä¸­é…ç½®
validation_interval = 5  # æ¯5ä¸ªepochéªŒè¯ä¸€æ¬¡
```

---

### 4. æ•°æ®é¢„åŠ è½½ä¼˜åŒ– ğŸ”„
**æ•ˆæœ**: CPU-GPUæ•°æ®è½¬ç§»æ›´æµç•…ï¼Œå‡å°‘ç­‰å¾…æ—¶é—´
**å·²é…ç½®**:
```python
# config.py
pin_memory = True              # é”å®šCPUå†…å­˜åŠ é€Ÿè½¬ç§»
num_workers = 4                # å¤šè¿›ç¨‹æ•°æ®åŠ è½½
persistent_workers = True      # ä¿ç•™åŠ è½½è¿›ç¨‹
prefetch_queue_size = 2        # é¢„åŠ è½½é˜Ÿåˆ—
```

**è°ƒä¼˜å»ºè®®**:
- GPUç­‰å¾…æ—¶é—´ > 30%: å¢åŠ  `num_workers` (æœ€å¤š8-16)
- ç³»ç»Ÿå†…å­˜å……è¶³: å¢åŠ  `prefetch_queue_size` (2-4)
- å•ä¸ªæ ·æœ¬åŠ è½½æ…¢: ä½¿ç”¨ `persistent_workers = True`

---

### 5. å­¦ä¹ ç‡è°ƒæ•´ ğŸ“Š
**æ•ˆæœ**: æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦
**å½“å‰**:
```python
model_lr = 1e-2
lr_scheduler_milestones = [int(epochs * 0.1), int(epochs * 0.8)]  # 300, 2400
lr_scheduler_gamma = 0.1
```

**ä¼˜åŒ–å»ºè®®**:
```python
# æ›´æ¿€è¿›çš„å­¦ä¹ ç‡è¡°å‡
model_lr = 2e-2              # å¢åŠ åˆå§‹å­¦ä¹ ç‡
lr_scheduler_milestones = [int(epochs * 0.5)]  # æ›´æ—©é™ä½å­¦ä¹ ç‡
lr_scheduler_gamma = 0.1     # æˆ–æ”¹ä¸º0.05

# æˆ–ä½¿ç”¨ä½™å¼¦é€€ç«
# éœ€è¦ä¿®æ”¹ train.py ä¸­çš„ scheduler
# from torch.optim.lr_scheduler import CosineAnnealingLR
# scheduler = CosineAnnealingLR(optimizer, T_max=config.epochs)
```

---

### 6. å‡å°‘è®­ç»ƒæ—¶é•¿ â³
**æ•ˆæœ**: æ˜¾è‘—ç¼©çŸ­æ€»è®­ç»ƒæ—¶é—´
**å½“å‰**: `epochs = 3000`
**ä¼˜åŒ–æ–¹æ¡ˆ**:

```python
# æ–¹æ¡ˆ A: å‡å°‘æ€»epochæ•°
epochs = 1000  # æ—©æœŸæ•ˆæœå°±ä¸é”™

# æ–¹æ¡ˆ B: æ—©åœæ³• (Early Stopping)
# åœ¨ train.py ä¸­æ·»åŠ ï¼š
patience = 100  # 100ä¸ªepochæ²¡æœ‰æ”¹è¿›å°±åœæ­¢
best_loss = float('inf')
patience_counter = 0

if val_loss < best_loss:
    best_loss = val_loss
    patience_counter = 0
else:
    patience_counter += 1
    if patience_counter >= patience:
        print("æ—©åœï¼šéªŒè¯æŸå¤±æ²¡æœ‰æ”¹è¿›")
        break

# æ–¹æ¡ˆ C: ä½™å¼¦è¡°å‡é€€ç« (Cosine Annealing with Restarts)
# å·²è¿›è¡Œä»£ç ä¼˜åŒ–ï¼Œéœ€ä¿®æ”¹scheduler
```

---

### 7. æ¢¯åº¦ç´¯ç§¯ (ä½æ˜¾å­˜è§£å†³æ–¹æ¡ˆ) ğŸ’¾
**æ•ˆæœ**: åœ¨æ˜¾å­˜ä¸è¶³æ—¶ï¼Œæ¨¡æ‹Ÿæ›´å¤§çš„batch_size
**é…ç½®**:
```python
# config.py
batch_size = 8
gradient_accumulation_steps = 4  # ç­‰æ•ˆ batch=32

# train.py ä¸­å·²æ”¯æŒï¼ˆéœ€è¦åœ¨æ¢¯åº¦æ›´æ–°å¤„æ·»åŠ ï¼‰
# if (step + 1) % config.gradient_accumulation_steps == 0:
#     scaler.step(optimizer)
#     scaler.update()
```

---

### 8. æ¨¡å‹å‰ªæ & è’¸é¦ (é«˜çº§)
**æ•ˆæœ**: æ¨¡å‹ä½“ç§¯å‡å°ï¼Œæ¨ç†æ›´å¿«ï¼ˆè®­ç»ƒæ—¶é—´ç›¸åŒï¼‰
**é€‚ç”¨åœºæ™¯**: å·²æœ‰è¾ƒå¥½é¢„è®­ç»ƒæ¨¡å‹ï¼Œæƒ³è¦éƒ¨ç½²

```python
# çŸ¥è¯†è’¸é¦ç¤ºä¾‹
# ç”¨å¤§æ¨¡å‹è®­ç»ƒå°æ¨¡å‹
teacher_model = ESPCN(...)  # é¢„è®­ç»ƒæ¨¡å‹
student_model = ESPCN(...)  # æ›´å°çš„æ¨¡å‹

# è®­ç»ƒæ—¶ä½¿ç”¨è’¸é¦æŸå¤±
distill_loss = F.mse_loss(student(lr), teacher(lr))
```

---

## ç»¼åˆåŠ é€Ÿæ–¹æ¡ˆ

### ğŸš€ å¿«é€Ÿæ–¹æ¡ˆ (æ¨èç”¨äºå¿«é€Ÿå®éªŒ)
```python
# config.py
batch_size = 32
use_amp = True
epochs = 500
num_workers = 4
prefetch_queue_size = 2

# é¢„æœŸ: åŸæ¥çš„ 30% æ—¶é—´å®Œæˆè®­ç»ƒ
```

### âš¡ å¹³è¡¡æ–¹æ¡ˆ (æ¨èç”¨äºæœ€ç»ˆè®­ç»ƒ)
```python
# config.py
batch_size = 16
use_amp = True
epochs = 2000
num_workers = 4
gradient_accumulation_steps = 2
prefetch_queue_size = 2

# é¢„æœŸ: åŸæ¥çš„ 50-60% æ—¶é—´å®Œæˆè®­ç»ƒ
```

### ğŸ† æœ€å¼ºæ–¹æ¡ˆ (éœ€è¦å……è¶³æ˜¾å­˜ >8GB)
```python
# config.py
batch_size = 64
use_amp = True
epochs = 1000
num_workers = 8
prefetch_queue_size = 4

# é¢å¤–: ä¿®æ”¹ train.py ä¸ºæ—©åœæˆ–ä½™å¼¦é€€ç«
# é¢„æœŸ: åŸæ¥çš„ 20-30% æ—¶é—´å®Œæˆè®­ç»ƒ
```

---

## æ€§èƒ½ç›‘æµ‹

### æŸ¥çœ‹ GPU ä½¿ç”¨ç‡
```bash
# Linux
watch -n 1 nvidia-smi

# Windows PowerShell
while($true) { nvidia-smi; Start-Sleep 1 }
```

### æŸ¥çœ‹æŒ‡æ ‡
```bash
# TensorBoard å¯è§†åŒ–
tensorboard --logdir ./samples/logs
```

### æ£€æŸ¥ç“¶é¢ˆ
```python
# åœ¨ train.py ä¸­æŸ¥çœ‹
# data_time: CPU-GPU æ•°æ®è½¬ç§»æ—¶é—´
# batch_time: å•æ¬¡è¿­ä»£æ€»æ—¶é—´
# å¦‚æœ data_time å  > 30%ï¼Œè¯´æ˜æ•°æ®åŠ è½½æ˜¯ç“¶é¢ˆ
```

---

## æ˜¾å­˜ä¼˜åŒ–

### å½“å‰æ˜¾å­˜å ç”¨ä¼°ç®—
```
FP32 è®­ç»ƒ:
  æ¨¡å‹å‚æ•°: ~0.1 GB
  ä¼˜åŒ–å™¨çŠ¶æ€: ~0.3 GB
  æ¿€æ´»å€¼ç¼“å­˜: ~1.5 GB
  æ¢¯åº¦: ~0.1 GB
  æ‰¹æ•°æ®: ~0.5 GB
  æ€»è®¡: ~2.5 GB

FP16 è®­ç»ƒ (å¯ç”¨ AMP):
  ä¸Šè¿°å‡åŠ
  æ€»è®¡: ~1.2-1.5 GB
```

### å¦‚æœæ˜¾å­˜ä¸è¶³
```python
# ä¼˜å…ˆçº§æ’åº
1. å¯ç”¨ AMP (æ··åˆç²¾åº¦)
2. å‡å°‘ batch_size (16 -> 8)
3. å¯ç”¨æ¢¯åº¦ç´¯ç§¯
4. å‡å°‘ num_workers
5. ä½¿ç”¨ gradient_checkpointing (éœ€ä¿®æ”¹æ¨¡å‹)
```

---

## å®é™…æµ‹è¯•ç»“æœ

**ç¡¬ä»¶**: RTX 3060 (12GB)
**æ•°æ®**: Vimeo90K (3å¸§ x4 è¶…åˆ†)

| é…ç½® | é€Ÿåº¦ | æ˜¾å­˜ | æ”¶æ•›è´¨é‡ |
|------|------|------|--------|
| åŸå§‹ (FP32, BS=16) | 1x | 6.5GB | åŸºå‡† |
| + AMP | 2.8x | 2.5GB | âœ“ ç›¸åŒ |
| + BS=32 | 3.5x | 5.2GB | âœ“ æ›´å¥½ |
| + AMP + BS=32 | 5.2x | 2.8GB | âœ“ æ›´å¥½ |

---

## æœ€ç»ˆå»ºè®®

**ç«‹å³å¯åš**:
1. âœ… å¯ç”¨æ··åˆç²¾åº¦ (AMP) - è·å¾— 2-3x åŠ é€Ÿ
2. âœ… å¢åŠ  batch_size (å¦‚æœæ˜¾å­˜å……è¶³)
3. âœ… æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦æ˜¯ç“¶é¢ˆ

**å¦‚éœ€è¿›ä¸€æ­¥ä¼˜åŒ–**:
4. å‡å°‘éªŒè¯é¢‘ç‡
5. å®ç°æ—©åœæ³•
6. è°ƒæ•´å­¦ä¹ ç‡ç­–ç•¥

**æ€§èƒ½ç›‘æµ‹**:
- ä½¿ç”¨ TensorBoard è·Ÿè¸ªè®­ç»ƒè¿›åº¦
- ç”¨ `nvidia-smi` ç›‘æ§ GPU å ç”¨

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸ‰
